{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Google Colab users - Mounting Google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive') # I tend to call my drive gdrive,if your name is Kelly you can kall it kellydrive as well ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import imutils\n",
    "import snoop\n",
    "# Uncomment below line, if you are using google-colab, since cv2.imshow should be substituted by cv2_imshow in colab\n",
    "#from google.colab.patches import cv2_imshow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd()) #current directory path\n",
    "print(os.listdir()) # current directory contents, as we can see our google-drive has been successfully mounted at gdrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work in a virtual environment with python==3.6 & virtualenvwrapper and virtualenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install virtualenv \n",
    "!pip install virtualenvwrapper\n",
    "# Also add the following line to your ~/.bashrc file < source /usr/local/bin/virtaulenvwrapper.sh > in case\n",
    "# you have miniconda/anaconda installed see < PathToYourMiniconda3Directory/bin/virtualenvwrapper.sh >\n",
    "\n",
    "# If you are using jupyter-lab opening a separate terminal tab might be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkvirtualenv --python=/usr/bin/python3.6 env\n",
    "!workon env\n",
    "# And then pip install the required packages, to exit virtualenv just type deactivate ['Enter']\n",
    "# Using virtualenv and virtualenvwrapper to handle virtualenv can be great tools in your artillery, I\n",
    "# recommend using virtualenv instead of venv (don't be mislead, it can/should be used with python3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the youtube video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing youtube-dl for downloading videos from youtube on linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apt (i.e ubuntu) has a really outdated version of youtube-dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-cache showpkg youtube-dl | grep \"ubuntu18.04\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use pip to install youtube-dl , youtube-dl has daily to weekly updates as can be seen from the date 2019.12.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade youtube_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading the news video in our current directory with youtube-dl\n",
    "[Speed News | Top Headlines Of The Day | India Today | Dec 27, 2019](https://www.youtube.com/watch?v=so4H-taPJgE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!youtube-dl https://www.youtube.com/watch?v=so4H-taPJgE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The video will be present in our current directory as we can see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Frames from the video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Firstly, I'll create a new sub-directory to store the frames, named news_frames( all the frames) and nframes1s ( having 1 frame per second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('news_frames'):\n",
    "    shutil.rmtree('news_frames')\n",
    "if os.path.exists('nframes1s'):\n",
    "    shutil.rmtree('nframes1s')\n",
    "os.mkdir('news_frames')\n",
    "os.mkdir('nframes1s')\n",
    "print(os.listdir()) # news_frames has been created, as can be seen by the output of os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Info : Frame rate and duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -i Speed\\ News\\ _\\ Top\\ Headlines\\ Of\\ The\\ Day\\ _\\ India\\ Today\\ _\\ Dec\\ 27,\\ 2019-so4H-taPJgE.mkv 2>&1 | sed -n \"s/.*, \\(.*\\) tbr.*/\\1/p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -i Speed\\ News\\ _\\ Top\\ Headlines\\ Of\\ The\\ Day\\ _\\ India\\ Today\\ _\\ Dec\\ 27,\\ 2019-so4H-taPJgE.mkv 2>&1 | grep \"Duration\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of frames from news video to news_frames directory using ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1 frame per second extraction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -i Speed\\ News\\ _\\ Top\\ Headlines\\ Of\\ The\\ Day\\ _\\ India\\ Today\\ _\\ Dec\\ 27,\\ 2019-so4H-taPJgE.mkv -vf fps=1 nframes1s/image_%04d.png -hide_banner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`No. of frames and contents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'No. of frames saved in nframes1s: {len(os.listdir(\"nframes1s\"))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Full Frames extraction : Relevant when each frame has high amount of data, such as in Indian news headlines scenario`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -i Speed\\ News\\ _\\ Top\\ Headlines\\ Of\\ The\\ Day\\ _\\ India\\ Today\\ _\\ Dec\\ 27,\\ 2019-so4H-taPJgE.mkv news_frames/image_%04d.png -hide_banner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of frames: {}'.format(len(os.listdir('news_frames')))) # Number of frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A sample frame from the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"nframes1s/image_0010.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning for Text Detection, code taken from Adrien Rosebrock's blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Pyimagesearch EAST text detector](https://www.pyimagesearch.com/2018/08/20/opencv-text-detection-east-text-detector/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Download the zip file containing the model file and python scripts for east text detection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/opencv-text-detection/opencv-text-detection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip opencv-text-detection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir('opencv-text-detection/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Move files from opencv-text-detection to current working directory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('opencv-text-detection')\n",
    "for f in os.listdir():\n",
    "  shutil.move(f, '..')\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd()) \n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Test Detection on a single image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python text_detection.py --image nframes1s/image_0101.png \\\n",
    "\t--east frozen_east_text_detection.pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python file to run text detection on directory of images - text_detection_wrapper.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile text_detection_wrapper.py\n",
    "\n",
    "## Creating text_detection_wrapper.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from text_detection import detect_fun\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--directory\", type=str,\n",
    "\thelp=\"path to input directory\")\n",
    "ap.add_argument(\"-f\", \"--out\", type=str,\n",
    "   help='path to output directory')\n",
    "ap.add_argument(\"-c\", \"--min-confidence\", type=float, default=0.5,\n",
    "\thelp=\"minimum probability required to inspect a region\")\n",
    "ap.add_argument( '-cr', \"--crop\", action='store_true')\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "for img in sorted(os.listdir(args['directory'])):\n",
    "  detect_fun(os.path.join(args['directory'],img), args['out'], args['crop'], args['min_confidence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 arguments can be given to text_detection_wrapper.py , input directory, output directory, min_confidence and <br> <font color=green>crop (whether to crop the detections or to draw bounding boxes on them and save the image)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modify text_detection.py to work with text_detection_wrapper and with a directory of imagees, instead of single images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile text_detection.py\n",
    "\n",
    "# import the necessary packages\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "#import snoop\n",
    "#from google.colab.patches import cv2_imshow (If working on google-colab)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#@snoop\n",
    "def detect_fun(image, img_dir, crop=False, conf=0.5):\n",
    "    args = {}\n",
    "    args['image'] = image\n",
    "    args['east'] = 'frozen_east_text_detection.pb'\n",
    "    args['min_confidence'] = conf\n",
    "    args['width'] = 320\n",
    "    args['height'] = 320\n",
    "\n",
    "    # load the input image and grab the image dimensions\n",
    "    image = cv2.imread(args[\"image\"])\n",
    "    orig = image.copy()\n",
    "    (H, W) = image.shape[:2]\n",
    "\n",
    "    # set the new width and height and then determine the ratio in change\n",
    "    # for both the width and height\n",
    "    (newW, newH) = (args[\"width\"], args[\"height\"])\n",
    "    rW = W / float(newW)\n",
    "    rH = H / float(newH)\n",
    "\n",
    "    # resize the image and grab the new image dimensions\n",
    "    image = cv2.resize(image, (newW, newH))\n",
    "    (H, W) = image.shape[:2]\n",
    "\n",
    "    # define the two output layer names for the EAST detector model that\n",
    "    # we are interested -- the first is the output probabilities and the\n",
    "    # second can be used to derive the bounding box coordinates of text\n",
    "    layerNames = [\n",
    "      \"feature_fusion/Conv_7/Sigmoid\",\n",
    "      \"feature_fusion/concat_3\"]\n",
    "\n",
    "    # load the pre-trained EAST text detector\n",
    "    print(\"[INFO] loading EAST text detector...\")\n",
    "    net = cv2.dnn.readNet(args[\"east\"])\n",
    "\n",
    "    # construct a blob from the image and then perform a forward pass of\n",
    "    # the model to obtain the two output layer sets\n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n",
    "      (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "    start = time.time()\n",
    "    net.setInput(blob)\n",
    "    (scores, geometry) = net.forward(layerNames)\n",
    "    end = time.time()\n",
    "\n",
    "    # show timing information on text prediction\n",
    "    print(\"[INFO] text detection took {:.6f} seconds\".format(end - start))\n",
    "\n",
    "    # grab the number of rows and columns from the scores volume, then\n",
    "    # initialize our set of bounding box rectangles and corresponding\n",
    "    # confidence scores\n",
    "    (numRows, numCols) = scores.shape[2:4]\n",
    "    rects = []\n",
    "    confidences = []\n",
    "\n",
    "    # loop over the number of rows\n",
    "    for y in range(0, numRows):\n",
    "      # extract the scores (probabilities), followed by the geometrical\n",
    "      # data used to derive potential bounding box coordinates that\n",
    "      # surround text\n",
    "      scoresData = scores[0, 0, y]\n",
    "      xData0 = geometry[0, 0, y]\n",
    "      xData1 = geometry[0, 1, y]\n",
    "      xData2 = geometry[0, 2, y]\n",
    "      xData3 = geometry[0, 3, y]\n",
    "      anglesData = geometry[0, 4, y]\n",
    "\n",
    "\n",
    "    # loop over the number of columns\n",
    "      for x in range(0, numCols):\n",
    "        # if our score does not have sufficient probability, ignore it\n",
    "        if scoresData[x] < args[\"min_confidence\"]:\n",
    "          continue\n",
    "\n",
    "        # compute the offset factor as our resulting feature maps will\n",
    "        # be 4x smaller than the input image\n",
    "        (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "\n",
    "        # extract the rotation angle for the prediction and then\n",
    "        # compute the sin and cosine\n",
    "        angle = anglesData[x]\n",
    "        cos = np.cos(angle)\n",
    "        sin = np.sin(angle)\n",
    "\n",
    "        # use the geometry volume to derive the width and height of\n",
    "        # the bounding box\n",
    "        h = xData0[x] + xData2[x]\n",
    "        w = xData1[x] + xData3[x]\n",
    "\n",
    "        # compute both the starting and ending (x, y)-coordinates for\n",
    "        # the text prediction bounding box\n",
    "        endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "        endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "        startX = int(endX - w)\n",
    "        startY = int(endY - h)\n",
    "\n",
    "        # add the bounding box coordinates and probability score to\n",
    "        # our respective lists\n",
    "        rects.append((startX, startY, endX, endY))\n",
    "        confidences.append(scoresData[x])\n",
    "\n",
    "\n",
    "      # apply non-maxima suppression to suppress weak, overlapping bounding\n",
    "    # boxes\n",
    "    boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "    \n",
    "    if not os.path.exists(img_dir):\n",
    "      os.mkdir(img_dir)\n",
    "\n",
    "    # loop over the bounding boxes\n",
    "    for (i ,(startX, startY, endX, endY)) in enumerate(boxes):\n",
    "      # scale the bounding box coordinates based on the respective\n",
    "      # ratios\n",
    "      startX = int(startX * rW)\n",
    "      startY = int(startY * rH)\n",
    "      endX = int(endX * rW)\n",
    "      endY = int(endY * rH)\n",
    "      \n",
    "      if crop == True:\n",
    "        crop_img = orig[startY -5: endY + 5, startX -5:endX + 5]\n",
    "        cv2.imwrite(os.path.join(img_dir, args['image'].split('/')[1][:-4] + '_' + str(i) + '.png'), crop_img)\n",
    "        print('Writing image to : {}'.format(os.path.join(img_dir, args['image'].split('/')[1][:-4] + '_' + str(i) + '.png')))\n",
    "      else:\n",
    "      # draw the bounding box on the image\n",
    "        cv2.rectangle(orig, (startX, startY), (endX, endY), (255, 0, 0), 4)\n",
    "\n",
    "      #cv2_imshow(crop_img)\n",
    "\n",
    "    # show the output image\n",
    "    #plt.imshow(orig)\n",
    "    #print(args['image'].split('/'))\n",
    "    if not crop:\n",
    "      #print(f\"Path is {os.path.join(img_dir, args['image'].split('/')[1])}\")\n",
    "      if not cv2.imwrite(os.path.join(img_dir, args['image'].split('/')[1]), orig):\n",
    "            print(os.path.join(img_dir, args['image'].split('/')[1]))\n",
    "      print('Writing image to : {}'.format(os.path.join(img_dir, args['image'].split('/')[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Currently extracts the detections from the frames and then saves them to results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists('results'):\n",
    "    shutil.rmtree('results/')\n",
    "os.mkdir('results')\n",
    "!python text_detection_wrapper.py --directory nframes1s/ --out results --min-confidence 0.5 -cr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To create video file for Indian news headlines video actual frame rate would be better, but for a video from bbc, 1 frames per second will do just fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists('detections'):\n",
    "    shutil.rmtree('detections/')\n",
    "!python text_detection_wrapper.py --directory news_frames --out detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video from frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -framerate 25 -i detections/image_%04d.png speed_news.mp4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CRNN for text - recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Model by Bai-shang\n",
    "<font color=blue>[CRNN bai-shang](https://github.com/bai-shang/crnn_ctc_ocr.Tensorflow)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/bai-shang/crnn_ctc_ocr.Tensorflow.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('crnn_ctc_ocr.Tensorflow/')\n",
    "print(os.getcwd())\n",
    "!export PYTHONPATH=$PYTHONPATH:./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://drive.google.com/uc?export=download&confirm=5JEV&id=1A3V7o3SKSiL3IHcTqc1jP4w58DuC8F9o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip ../bs_synth90k_model.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create image_list.txt for our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../image_list.txt', 'w') as f:\n",
    "  for img in os.listdir('../results'):\n",
    "    f.write(img + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifying tools/inference_crnn_ctc.py\n",
    "\n",
    "`Adding path to crnn_ctc_ocr.Tensorflow directly is required, so use sys.path.append as shown below`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tools/inference_crnn_ctc.py\n",
    "\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('/home/valuepitch/.Private/text_recognition_in_news_videos/crnn_ctc_ocr.Tensorflow')\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from crnn_model import model\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "_IMAGE_HEIGHT = 32\n",
    "\n",
    "# ------------------------------------Basic prameters------------------------------------\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'image_dir', './test_data/images/', 'Path to the directory containing images.')\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'image_list', './test_data/image_list.txt', 'Path to the images list txt file.')\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'model_dir', './model/', 'Base directory for the model.')\n",
    "\n",
    "# ------------------------------------LSTM prameters------------------------------------\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'lstm_hidden_layers', 2, 'The number of stacked LSTM cell.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'lstm_hidden_uints', 256, 'The number of units in each LSTM cell')\n",
    "\n",
    "# ------------------------------------Char dictionary------------------------------------\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'char_map_json_file', './char_map/char_map.json', 'Path to char map json file')\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "def _sparse_matrix_to_list(sparse_matrix, char_map_dict=None):\n",
    "    indices = sparse_matrix.indices\n",
    "    values = sparse_matrix.values\n",
    "    dense_shape = sparse_matrix.dense_shape\n",
    "\n",
    "    # the last index in sparse_matrix is ctc blanck note\n",
    "    if char_map_dict is None:\n",
    "        char_map_dict = json.load(open(FLAGS.char_map_json_file, 'r'))\n",
    "    assert(isinstance(char_map_dict, dict) and 'char_map_dict is not a dict')    \n",
    "\n",
    "    dense_matrix =  len(char_map_dict.keys()) * np.ones(dense_shape, dtype=np.int32)\n",
    "    for i, indice in enumerate(indices):\n",
    "        dense_matrix[indice[0], indice[1]] = values[i]\n",
    "    string_list = []\n",
    "    for row in dense_matrix:\n",
    "        string = []\n",
    "        for val in row:\n",
    "            string.append(_int_to_string(val, char_map_dict))\n",
    "        string_list.append(''.join(s for s in string if s != '*'))\n",
    "    return string_list\n",
    "\n",
    "def _int_to_string(value, char_map_dict=None):\n",
    "    if char_map_dict is None:\n",
    "        char_map_dict = json.load(open(FLAGS.char_map_json_file, 'r'))\n",
    "    assert(isinstance(char_map_dict, dict) and 'char_map_dict is not a dict')\n",
    "    \n",
    "    for key in char_map_dict.keys():\n",
    "        if char_map_dict[key] == int(value):\n",
    "            return str(key)\n",
    "        elif len(char_map_dict.keys()) == int(value):\n",
    "            return \"\" \n",
    "    raise ValueError('char map dict not has {:d} value. convert index to char failed.'.format(value))\n",
    "\n",
    "def _inference_crnn_ctc():\n",
    "    input_image = tf.placeholder(dtype=tf.float32, shape=[1, _IMAGE_HEIGHT, None, 3])\n",
    "    char_map_dict = json.load(open(FLAGS.char_map_json_file, 'r'))\n",
    "    # initialise the net model\n",
    "    crnn_net = model.CRNNCTCNetwork(phase='test',\n",
    "                                    hidden_num=FLAGS.lstm_hidden_uints,\n",
    "                                    layers_num=FLAGS.lstm_hidden_layers,\n",
    "                                    num_classes=len(char_map_dict.keys()) + 1)\n",
    "\n",
    "    with tf.variable_scope('CRNN_CTC', reuse=False):\n",
    "        net_out = crnn_net.build_network(input_image)\n",
    "\n",
    "    input_sequence_length = tf.placeholder(tf.int32, shape=[1], name='input_sequence_length')\n",
    "\n",
    "    ctc_decoded, ct_log_prob = tf.nn.ctc_beam_search_decoder(net_out, input_sequence_length, merge_repeated=True)\n",
    "\n",
    "    with open(FLAGS.image_list, 'r') as fd:\n",
    "       image_names = [line.strip() for line in fd.readlines()]\n",
    "\n",
    "    # set checkpoint saver\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = tf.train.latest_checkpoint(FLAGS.model_dir)\n",
    "    \n",
    "    if os.path.exists('./text_recognition.txt'):\n",
    "      os.remove('text_recognition.txt')\n",
    "    \n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # restore all variables\n",
    "        saver.restore(sess=sess, save_path=save_path)\n",
    "        list1 = []\n",
    "        x = 1\n",
    "        for image_name in sorted(image_names):\n",
    "            try:\n",
    "                image_path = os.path.join(FLAGS.image_dir, image_name)\n",
    "                image = cv2.imread(image_path)\n",
    "                try:\n",
    "                  h, w, c = image.shape\n",
    "                  height = _IMAGE_HEIGHT\n",
    "                  width = int(w * height / h)\n",
    "                  image = cv2.resize(image, (width, height))\n",
    "                  image = np.expand_dims(image, axis=0)\n",
    "                  image = np.array(image, dtype=np.float32)\n",
    "                  seq_len = np.array([width / 4], dtype=np.int32)\n",
    "\n",
    "                  preds = sess.run(ctc_decoded, feed_dict={input_image:image, input_sequence_length:seq_len})\n",
    "\n",
    "                  preds = _sparse_matrix_to_list(preds[0], char_map_dict)\n",
    "\n",
    "\n",
    "                  print(\"here\")\n",
    "                  with open('text_recognition.txt', 'a') as f:\n",
    "                    if int(image_name[6:10]) == x:\n",
    "                      list1.append(preds[0])\n",
    "                    else:\n",
    "                      #import pdb ; pdb.set_trace()\n",
    "                      f.write('frame' + str(x) + ':' + ' ' + ' '.join(list1) + '\\n')\n",
    "                      list1 = []\n",
    "                      list1.append(preds[0])\n",
    "                      x+=1\n",
    "\n",
    "                  print('Predict {:s} image as: {:s}'.format(image_name, preds[0]))\n",
    "                except AttributeError:\n",
    "                  continue\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "def main(unused_argv):\n",
    "    _inference_crnn_ctc()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output from Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python tools/inference_crnn_ctc.py \\\n",
    "  --image_dir ../results/ --image_list ../image_list.txt \\\n",
    "  --model_dir bs_synth90k_model/ 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat text_recognition.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The output isn't as good as we would have liked it to be : Some solutions can be to :\n",
    "1) Add training data, we can do this by using a textgenerator, which I'm going to show how to do, we have to get the font type and save the .ttf file too.\n",
    "2) Some text detected like the word \"India Today\" is in every frame and should obviously be removed, since it's the channels name alone.\n",
    "3) The words have diverse backgrounds, like dark brown, brown, red, etc, so we can try adding those type of backgrounds in belval's textdatagenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check the output with tesseract-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install tesseract using the following command from the command line in a terminal\n",
    "!sudo apt update \n",
    "!sudo apt install tesseract-ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see tesseract completely fails on many of these images, and gives bad results on the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_0001_0.png \n",
      "image_0002_0.png \n",
      "image_0002_1.png \n",
      "image_0002_2.png \n",
      "image_0002_3.png \n",
      "image_0002_4.png \n",
      "image_0002_5.png ea!\n",
      "image_0003_0.png NEWS\n",
      "image_0003_1.png \n",
      "image_0003_2.png \n",
      "image_0003_3.png \n",
      "image_0003_4.png \n",
      "image_0003_5.png peed\n",
      "image_0003_6.png pie eee aoe\n",
      "image_0003_7.png aaa\n",
      "\n",
      "ea!\n",
      "image_0003_8.png \n",
      "image_0004_0.png NEWS\n",
      "image_0004_1.png \n",
      "image_0004_10.png \n",
      "image_0004_11.png LADAKH\n",
      "image_0004_12.png killed—\n",
      "image_0004_13.png \n",
      "image_0004_14.png LoC\n",
      "image_0004_15.png \n",
      "image_0004_16.png \n",
      "image_0004_17.png \n",
      "image_0004_18.png \n",
      "image_0004_19.png \n",
      "image_0004_2.png . KILLED\n",
      "image_0004_20.png C IN\n",
      "image_0004_3.png \n",
      "image_0004_4.png \n",
      "image_0004_5.png a2)\n",
      "image_0004_6.png BACK\n",
      "image_0004_7.png \n",
      "image_0004_8.png rite\n",
      "image_0004_9.png NTERNET\n",
      "image_0005_0.png NEWS\n",
      "image_0005_1.png \n",
      "image_0005_10.png \n",
      "image_0005_11.png SPEED\n",
      "image_0005_12.png \n",
      "image_0005_13.png ‘killed |\n",
      "image_0005_14.png \n",
      "image_0005_15.png \n",
      "image_0005_16.png along |\n",
      "image_0005_17.png Eile\n",
      "image_0005_18.png \n",
      "image_0005_19.png \n",
      "image_0005_2.png \n",
      "image_0005_20.png NOILVI\n",
      "image_0005_21.png \n",
      "image_0005_22.png \n",
      "image_0005_3.png \n",
      "image_0005_4.png \n",
      "image_0005_5.png BACK |\n",
      "image_0005_6.png af\n",
      "image_0005_7.png soldiers\n",
      "image_0005_8.png NTERNET |\n",
      "image_0005_9.png \n",
      "image_0006_0.png NEWS\n",
      "image_0006_1.png \n",
      "image_0006_10.png \n",
      "image_0006_11.png m7. 4\n",
      "image_0006_12.png \n",
      "image_0006_13.png killed .\n",
      "image_0006_14.png along /\n",
      "image_0006_15.png Eile\n",
      "image_0006_16.png \n",
      "image_0006_17.png KARGIL,\n",
      "image_0006_18.png \n",
      "image_0006_19.png \n",
      "image_0006_2.png \n",
      "image_0006_20.png \n",
      "image_0006_21.png CIN\n",
      "image_0006_22.png  \n",
      "\n",
      "aE\n",
      "image_0006_23.png \n",
      "image_0006_3.png \n",
      "image_0006_4.png \n",
      "image_0006_5.png \n",
      "image_0006_6.png a}\n",
      "image_0006_7.png NTERNET\n",
      "image_0006_8.png soldiers\n",
      "image_0006_9.png SPEED\n",
      "image_0007_0.png \n",
      "image_0007_1.png \n",
      "image_0007_10.png \n",
      "image_0007_11.png BACK\n",
      "image_0007_12.png \n",
      "image_0007_13.png \n",
      "image_0007_14.png ile\n",
      "image_0007_15.png ‘along :\n",
      "image_0007_16.png KARGIL,\n",
      "image_0007_17.png \n",
      "image_0007_18.png \n",
      "image_0007_19.png \n",
      "image_0007_2.png Tos ce\n",
      "image_0007_20.png \n",
      "image_0007_21.png |\n",
      "image_0007_22.png 242 Pee\n",
      "image_0007_3.png \n",
      "image_0007_4.png \n",
      "image_0007_5.png \n",
      "image_0007_6.png 0;\n",
      "image_0007_7.png NTERNET |\n",
      "image_0007_8.png Polisi i=) a\n",
      "image_0007_9.png SPEED\n",
      "image_0008_0.png NEWS\n",
      "image_0008_1.png \n",
      "image_0008_10.png \n",
      "image_0008_11.png NTERNET |\n",
      "image_0008_12.png lett Rta Mien\n",
      "\n",
      "LADAKH\n",
      "image_0008_13.png ‘killed\n",
      "image_0008_14.png ile\n",
      "image_0008_15.png \n",
      "image_0008_16.png \n",
      "image_0008_17.png \n",
      "image_0008_18.png \n",
      "image_0008_19.png \n",
      "image_0008_2.png — —\n",
      "Bia\n",
      "image_0008_20.png CIN\n",
      "image_0008_21.png Site\n",
      "image_0008_3.png \n",
      "image_0008_4.png \n",
      "image_0008_5.png \n",
      "image_0008_6.png \n",
      "image_0008_7.png BACK\n",
      "image_0008_8.png \n",
      "image_0008_9.png soldiers\n",
      "image_0009_0.png NEWS\n",
      "image_0009_1.png \n",
      "image_0009_10.png \n",
      "image_0009_11.png \n",
      "image_0009_12.png \n",
      "image_0009_13.png CIN\n",
      "image_0009_14.png a!\n",
      "image_0009_2.png Ye\n",
      "\n",
      "ee\n",
      "\n",
      "3.\n",
      "image_0009_3.png \n",
      "image_0009_4.png BACK\n",
      "image_0009_5.png \n",
      "image_0009_6.png INTERNET\n",
      "image_0009_7.png LADAKH\n",
      "image_0009_8.png \n",
      "image_0009_9.png PAK\n",
      "image_0010_0.png NEWS\n",
      "image_0010_1.png \n",
      "image_0010_10.png Pak\n",
      "image_0010_11.png \n",
      "image_0010_12.png \n",
      "image_0010_13.png \n",
      "image_0010_14.png \n",
      "image_0010_15.png \n",
      "image_0010_16.png TEA\n",
      "image_0010_17.png \n",
      "image_0010_18.png FULE\n",
      "image_0010_19.png Se Bal\n",
      "image_0010_2.png \n",
      "image_0010_20.png \n",
      "image_0010_3.png retaliates\n",
      "image_0010_4.png > KILLEL\n",
      "image_0010_5.png \n",
      "image_0010_6.png NTERNET\n",
      "image_0010_7.png BACK\n",
      "image_0010_8.png \n",
      "image_0010_9.png \n",
      "image_0011_0.png NEWS\n",
      "image_0011_1.png \n",
      "image_0011_10.png Pak\n",
      "image_0011_11.png \n",
      "image_0011_12.png \n",
      "image_0011_13.png \n",
      "image_0011_14.png \n",
      "image_0011_15.png PAK\n",
      "image_0011_16.png A\n",
      "image_0011_17.png \n",
      "image_0011_18.png \n",
      "image_0011_19.png \n",
      "image_0011_2.png \n",
      "image_0011_20.png \n",
      "image_0011_3.png retaliates\n",
      "image_0011_4.png \n",
      "image_0011_5.png . KILLEL\n",
      "image_0011_6.png BACK\n",
      "image_0011_7.png NTERNET\n",
      "image_0011_8.png \n",
      "image_0011_9.png \n",
      "image_0012_0.png NEWS\n",
      "image_0012_1.png \n",
      "image_0012_10.png Pak\n",
      "image_0012_11.png \n",
      "image_0012_12.png \n",
      "image_0012_13.png \n",
      "image_0012_14.png \n",
      "image_0012_15.png \n",
      "image_0012_16.png PAK\n",
      "image_0012_17.png \n",
      "image_0012_18.png EAL\n",
      "image_0012_19.png qi\n",
      "image_0012_2.png retaliates\n",
      "image_0012_3.png \n",
      "image_0012_4.png KILLED\n",
      "image_0012_5.png ya\n",
      "image_0012_6.png BACK\n",
      "image_0012_7.png NTERNET\n",
      "image_0012_8.png \n",
      "image_0012_9.png \n",
      "image_0013_0.png NEWS\n",
      "image_0013_1.png \n",
      "image_0013_10.png \n",
      "image_0013_11.png Pak\n",
      "image_0013_12.png \n",
      "image_0013_13.png \n",
      "image_0013_14.png \n",
      "image_0013_15.png firing\n",
      "image_0013_16.png PAK\n",
      "image_0013_17.png \n",
      "image_0013_18.png \n",
      "image_0013_19.png \n",
      "image_0013_2.png \n",
      "image_0013_3.png retaliates\n",
      "image_0013_4.png \n",
      "image_0013_5.png \n",
      "image_0013_6.png vs\n",
      "\n",
      "rr\n",
      "\n",
      "3.12\n",
      "image_0013_7.png BACK\n",
      "image_0013_8.png ITERNET\n",
      "image_0013_9.png \n",
      "image_0014_0.png NEWS\n",
      "image_0014_1.png \n",
      "image_0014_10.png Pak\n",
      "image_0014_11.png \n",
      "image_0014_12.png \n",
      "image_0014_13.png \n",
      "image_0014_14.png ne\\ tole\n",
      "image_0014_15.png \n",
      "image_0014_16.png PAK\n",
      "image_0014_17.png —s\n",
      "a lS3\n",
      "image_0014_18.png eR ea]\n",
      "image_0014_19.png ia\n",
      "image_0014_2.png retaliates\n",
      "image_0014_3.png \n",
      "image_0014_4.png NEWS\n",
      "image_0014_5.png BACK\n",
      "image_0014_6.png KILLED\n",
      "image_0014_7.png \n",
      "image_0014_8.png NTERNET\n",
      "image_0014_9.png \n",
      "image_0015_0.png NEWS\n",
      "image_0015_1.png \n",
      "image_0015_10.png KARGIL,\n",
      "image_0015_11.png NOILVN\n",
      "image_0015_12.png \n",
      "image_0015_13.png \n",
      "image_0015_2.png \n",
      "image_0015_3.png SOLDIERS\n",
      "image_0015_4.png \n",
      "image_0015_5.png ITERNET\n",
      "image_0015_6.png BACK\n",
      "image_0015_7.png \n",
      "image_0015_8.png PAK\n",
      "image_0015_9.png \n",
      "image_0016_0.png \n",
      "image_0016_1.png NEWS\n",
      "image_0016_10.png blll\n",
      "Tee -Rajouri\n",
      "image_0016_11.png \n",
      "image_0016_12.png \n",
      "image_0016_13.png \n",
      "image_0016_14.png PAK\n",
      "image_0016_15.png TEA\n",
      "image_0016_16.png \n",
      "image_0016_17.png \n",
      "image_0016_18.png \n",
      "image_0016_19.png \n",
      "image_0016_2.png \n",
      "image_0016_3.png \n",
      "image_0016_4.png \n",
      "image_0016_5.png JTERNET\n",
      "image_0016_6.png \n",
      "image_0016_7.png r:7 tH 4\n",
      "image_0016_8.png \n",
      "image_0016_9.png \n",
      "image_0017_0.png \n",
      "image_0017_1.png NEWS\n",
      "image_0017_10.png LADAKH\n",
      "image_0017_11.png KARGIL,\n",
      "image_0017_12.png \n",
      "image_0017_13.png \n",
      "image_0017_14.png PAK\n",
      "image_0017_15.png \n",
      "image_0017_16.png A\n",
      "image_0017_17.png \n",
      "image_0017_18.png \n",
      "image_0017_2.png \n",
      "image_0017_3.png INTERNET\n",
      "image_0017_4.png \n",
      "image_0017_5.png \n",
      "image_0017_6.png BACK\n",
      "image_0017_7.png semanas\n",
      "NEWS\n",
      "image_0017_8.png \n",
      "image_0017_9.png Poonch-R:\n",
      "image_0018_0.png ,_ KILLED\n",
      "image_0018_1.png NEWS\n",
      "image_0018_10.png \n",
      "image_0018_11.png KARGIL,\n",
      "image_0018_12.png \n",
      "image_0018_13.png \n",
      "image_0018_14.png PAK |\n",
      "image_0018_15.png \n",
      "image_0018_16.png Poonch-\n",
      "image_0018_17.png \n",
      "image_0018_18.png \n",
      "image_0018_2.png ais\n",
      "image_0018_3.png ITERNET\n",
      "image_0018_4.png e723)\n",
      "image_0018_5.png \n",
      "image_0018_6.png \n",
      "image_0018_7.png BACK\n",
      "image_0018_8.png \n",
      "image_0018_9.png ‘h-Rajouri\n",
      "image_0019_0.png \n",
      "image_0019_1.png NEWS\n",
      "image_0019_10.png \n",
      "image_0019_11.png rete -Rajouri\n",
      "image_0019_12.png LADAKH\n",
      "image_0019_13.png ra-\\ te ae\n",
      "image_0019_14.png \n",
      "image_0019_15.png ret\n",
      "image_0019_16.png F\n",
      "image_0019_17.png PAK |\n",
      "image_0019_18.png \n",
      "image_0019_19.png CIN\n",
      "image_0019_2.png \n",
      "image_0019_20.png \n",
      "image_0019_3.png BACK\n",
      "image_0019_4.png \n",
      "image_0019_5.png INTERNET\n",
      "image_0019_6.png \n",
      "image_0019_7.png \n",
      "image_0019_8.png \n",
      "image_0019_9.png 3:\n",
      "“3 = D\n",
      "image_0020_0.png \n",
      "image_0020_1.png NEWS\n",
      "image_0020_10.png PAK |\n",
      "image_0020_11.png \n",
      "image_0020_12.png ert\n",
      "image_0020_13.png ee ded a\n",
      "image_0020_14.png \n",
      "image_0020_15.png \n",
      "image_0020_2.png \n",
      "image_0020_3.png \n",
      "image_0020_4.png \n",
      "image_0020_5.png \n",
      "image_0020_6.png Poonch-Raijouri\n",
      "image_0020_7.png ee\n",
      "_ SPEED NEWS\n",
      "image_0020_8.png \n",
      "image_0020_9.png \n",
      "image_0021_0.png \n",
      "image_0021_1.png \n",
      "image_0021_2.png \n",
      "image_0021_3.png \n",
      "image_0021_4.png \n",
      "image_0021_5.png rere\n",
      "image_0022_0.png \n",
      "image_0022_1.png \n",
      "image_0022_2.png \n",
      "image_0022_3.png \n",
      "image_0022_4.png eee. ae\n",
      "image_0022_5.png \n",
      "image_0022_6.png ea om\n",
      "image_0022_7.png ees\n",
      "image_0022_8.png \n",
      "image_0023_0.png \n",
      "image_0023_1.png \n",
      "image_0023_10.png \n",
      "image_0023_2.png NEWS\n",
      "image_0023_3.png \n",
      "image_0023_4.png \n",
      "image_0023_5.png \n",
      "image_0023_6.png STALIN,\n",
      "image_0023_7.png \n",
      "image_0023_8.png ATTEND\n",
      "image_0023_9.png emennenatimnel\n",
      "MAMATA 1\n",
      "image_0024_0.png NEWS\n",
      "image_0024_1.png \n",
      "image_0024_10.png \n",
      "image_0024_11.png ‘killed\n",
      "image_0024_12.png PAK :!\n",
      "image_0024_13.png ale a\n",
      "eevee ae\n",
      "image_0024_14.png ATTEND\n",
      "image_0024_15.png is)\n",
      "image_0024_16.png \n",
      "image_0024_17.png titania\n",
      "\n",
      "STALIN,\n",
      "image_0024_18.png \n",
      "image_0024_19.png \n",
      "image_0024_2.png \n",
      "image_0024_20.png \n",
      "image_0024_21.png \n",
      "image_0024_22.png a\n",
      "image_0024_3.png \n",
      "image_0024_4.png . KILLED\n",
      "image_0024_5.png \n",
      "image_0024_6.png \n",
      "image_0024_7.png f\n",
      "image_0024_8.png soldiers\n",
      "image_0024_9.png \n",
      "image_0025_0.png NEWS\n",
      "image_0025_1.png \n",
      "image_0025_10.png \n",
      "image_0025_11.png ‘killed\n",
      "image_0025_12.png Eilts\n",
      "image_0025_13.png \n",
      "image_0025_14.png \n",
      "image_0025_15.png \n",
      "image_0025_16.png STALIN,\n",
      "image_0025_17.png ry\\ wee\n",
      "image_0025_18.png \n",
      "image_0025_19.png \n",
      "image_0025_2.png \n",
      "image_0025_20.png er\n",
      "image_0025_21.png ra\n",
      "image_0025_3.png \n",
      "image_0025_4.png \n",
      "image_0025_5.png . KILLED\n",
      "image_0025_6.png \n",
      "image_0025_7.png sf\n",
      "image_0025_8.png soldiers\n",
      "image_0025_9.png \n",
      "image_0026_0.png NEWS\n",
      "image_0026_1.png \n",
      "image_0026_10.png \n",
      "image_0026_11.png \n",
      "image_0026_12.png \n",
      "image_0026_13.png \n",
      "image_0026_14.png PAK |:\n",
      "image_0026_15.png ile\n",
      "image_0026_16.png \n",
      "image_0026_17.png rvrv ty wee\n",
      "image_0026_18.png \n",
      "image_0026_19.png \n",
      "image_0026_2.png \n",
      "image_0026_20.png \n",
      "image_0026_21.png Steal\n",
      "image_0026_3.png \n",
      "image_0026_4.png \n",
      "image_0026_5.png \n",
      "image_0026_6.png af\n",
      "image_0026_7.png soldiers\n",
      "image_0026_8.png \n",
      "image_0026_9.png \n",
      "image_0027_0.png NEWS\n",
      "image_0027_1.png \n",
      "image_0027_10.png \n",
      "image_0027_11.png ki i led\n",
      "image_0027_12.png \n",
      "image_0027_13.png PAK |\n",
      "image_0027_14.png ile\n",
      "image_0027_15.png \n",
      "image_0027_16.png Sree\n",
      "image_0027_17.png Steet ieteineel\n",
      "\n",
      "MAMATA i\n",
      "image_0027_18.png \n",
      "image_0027_19.png \n",
      "image_0027_2.png \n",
      "image_0027_20.png \n",
      "image_0027_3.png \n",
      "image_0027_4.png \n",
      "image_0027_5.png af\n",
      "image_0027_6.png \n",
      "image_0027_7.png \n",
      "image_0027_8.png soldiers\n",
      "image_0027_9.png \n",
      "image_0028_0.png NEWS\n",
      "image_0028_1.png ae\n",
      "image_0028_10.png \n",
      "image_0028_11.png ‘killed\n",
      "image_0028_12.png relate\n",
      "\n",
      "STALIN,\n",
      "image_0028_13.png Ty we :\n",
      "image_0028_14.png PAK :!\n",
      "image_0028_15.png \n",
      "image_0028_16.png isle\n",
      "image_0028_17.png along\n",
      "image_0028_18.png \n",
      "image_0028_19.png \n",
      "image_0028_2.png \n",
      "image_0028_20.png \n",
      "image_0028_21.png Hirt\n",
      "image_0028_22.png \n",
      "image_0028_3.png . KILLED\n",
      "image_0028_4.png \n",
      "image_0028_5.png \n",
      "image_0028_6.png af\n",
      "image_0028_7.png soldiers\n",
      "image_0028_8.png \n",
      "image_0028_9.png \n",
      "image_0029_0.png NEWS\n",
      "image_0029_1.png \n",
      "image_0029_10.png \n",
      "image_0029_11.png \n",
      "image_0029_12.png \n",
      "image_0029_13.png \n",
      "image_0029_14.png PL\n",
      "image_0029_15.png Sw\n",
      "image_0029_16.png \n",
      "image_0029_17.png mn hie wx\n",
      "image_0029_2.png \n",
      "image_0029_3.png \n",
      "image_0029_4.png anette inne lll\n",
      "image_0029_5.png \n",
      "image_0029_6.png \n",
      "image_0029_7.png PAK\n",
      "image_0029_8.png yen\n",
      "image_0029_9.png \n",
      "image_0030_0.png NEWS\n",
      "image_0030_1.png ae\n",
      "image_0030_10.png STALIN,\n",
      "image_0030_11.png \n",
      "image_0030_12.png \n",
      "image_0030_13.png epee\n",
      "MAMATA T\n",
      "image_0030_14.png \n",
      "image_0030_15.png \n",
      "image_0030_16.png \n",
      "image_0030_17.png PAK\n",
      "image_0030_18.png \n",
      "image_0030_19.png \n",
      "image_0030_2.png \n",
      "image_0030_3.png \n",
      "image_0030_4.png \n",
      "image_0030_5.png retaliates\n",
      "image_0030_6.png KILLED\n",
      "image_0030_7.png \n",
      "image_0030_8.png Pak\n",
      "image_0030_9.png \n",
      "image_0031_0.png NEWS\n",
      "image_0031_1.png \n",
      "image_0031_10.png ry Wee\n",
      "image_0031_11.png \n",
      "image_0031_12.png ATTEND\n",
      "image_0031_13.png \n",
      "image_0031_14.png STALIN,\n",
      "image_0031_15.png \n",
      "image_0031_16.png PAK\n",
      "image_0031_17.png firing\n",
      "image_0031_18.png \n",
      "image_0031_19.png \n",
      "image_0031_2.png \n",
      "image_0031_20.png \n",
      "image_0031_21.png \n",
      "image_0031_3.png \n",
      "image_0031_4.png retaliates\n",
      "image_0031_5.png mw 4885\n",
      "image_0031_6.png \n",
      "image_0031_7.png SPEED\n",
      "image_0031_8.png Pak\n",
      "image_0031_9.png \n",
      "image_0032_0.png NEWS\n",
      "image_0032_1.png \n",
      "image_0032_10.png \n",
      "image_0032_11.png MAMATA *\n",
      "image_0032_12.png \n",
      "image_0032_13.png \n",
      "image_0032_14.png Sree\n",
      "image_0032_15.png \n",
      "image_0032_16.png PAK\n",
      "image_0032_17.png \n",
      "image_0032_18.png \n",
      "image_0032_19.png Z\n",
      "image_0032_2.png \n",
      "image_0032_3.png \n",
      "image_0032_4.png retaliates\n",
      "image_0032_5.png \n",
      "image_0032_6.png m4 88S\n",
      "image_0032_7.png \n",
      "image_0032_8.png \n",
      "image_0032_9.png Pak\n",
      "image_0033_0.png NEWS\n",
      "image_0033_1.png \n",
      "image_0033_10.png \n",
      "image_0033_11.png MAMATA °\n",
      "image_0033_12.png \n",
      "image_0033_13.png \n",
      "image_0033_14.png ee: ele\n",
      "image_0033_15.png \n",
      "image_0033_16.png \n",
      "image_0033_17.png PAK\n",
      "image_0033_18.png \n",
      "image_0033_19.png \n",
      "image_0033_2.png \n",
      "image_0033_20.png ea ewe\n",
      "image_0033_21.png \n",
      "image_0033_3.png \n",
      "image_0033_4.png retaliates\n",
      "image_0033_5.png \n",
      "image_0033_6.png \n",
      "image_0033_7.png \n",
      "image_0033_8.png \n",
      "image_0033_9.png Pak\n",
      "image_0034_0.png NEWS\n",
      "image_0034_1.png \n",
      "image_0034_10.png \n",
      "image_0034_11.png \n",
      "image_0034_12.png \n",
      "image_0034_13.png STALIN,\n",
      "image_0034_14.png MAMATA *\n",
      "image_0034_15.png \n",
      "image_0034_16.png \n",
      "image_0034_17.png PAK\n",
      "image_0034_18.png \n",
      "image_0034_19.png \n",
      "image_0034_2.png \n",
      "image_0034_20.png a\n",
      "image_0034_3.png \n",
      "image_0034_4.png retaliates\n",
      "image_0034_5.png KILLED\n",
      "image_0034_6.png SPEED\n",
      "image_0034_7.png \n",
      "image_0034_8.png Pak\n",
      "image_0034_9.png \n",
      "image_0035_0.png NEWS\n",
      "image_0035_1.png \n",
      "image_0035_10.png \n",
      "image_0035_11.png \n",
      "image_0035_12.png MAMATA 1\n",
      "image_0035_13.png \n",
      "image_0035_14.png \n",
      "image_0035_2.png \n",
      "image_0035_3.png \n",
      "image_0035_4.png \n",
      "image_0035_5.png \n",
      "image_0035_6.png \n",
      "image_0035_7.png i 4\n",
      "image_0035_8.png \n",
      "image_0035_9.png \n",
      "image_0036_0.png \n",
      "image_0036_1.png \n",
      "image_0036_10.png STALIN,\n",
      "image_0036_11.png MAMATA *\n",
      "image_0036_12.png \n",
      "image_0036_13.png \n",
      "image_0036_14.png \n",
      "image_0036_15.png \n",
      "image_0036_16.png PAK\n",
      "image_0036_17.png \n",
      "image_0036_18.png \n",
      "image_0036_2.png NEWS\n",
      "image_0036_3.png \n",
      "image_0036_4.png \n",
      "image_0036_5.png \n",
      "image_0036_6.png \n",
      "image_0036_7.png ities PT\n",
      "image_0036_8.png \n",
      "image_0036_9.png AY\n",
      "image_0037_0.png \n",
      "image_0037_1.png NEWS\n",
      "image_0037_10.png STALIN,\n",
      "image_0037_11.png \n",
      "image_0037_12.png \n",
      "image_0037_13.png \n",
      "image_0037_14.png \n",
      "image_0037_15.png \n",
      "image_0037_16.png PAK\n",
      "image_0037_17.png \n",
      "image_0037_2.png \n",
      "image_0037_3.png \n",
      "image_0037_4.png \n",
      "image_0037_5.png \n",
      "image_0037_6.png \n",
      "image_0037_7.png \n",
      "image_0037_8.png TTS eth a\n",
      "image_0037_9.png MAMATA *\n",
      "image_0038_0.png NEWS\n",
      "image_0038_1.png \n",
      "image_0038_10.png ATTEND\n",
      "image_0038_11.png MAMATA 1\n",
      "image_0038_12.png ee: ele\n",
      "image_0038_13.png \n",
      "image_0038_14.png \n",
      "image_0038_15.png \n",
      "image_0038_16.png \n",
      "image_0038_17.png PAK\n",
      "image_0038_18.png \n",
      "image_0038_19.png pepe\n",
      "image_0038_2.png \n",
      "image_0038_20.png \n",
      "image_0038_3.png \n",
      "image_0038_4.png \n",
      "image_0038_5.png \n",
      "image_0038_6.png \n",
      "image_0038_7.png \n",
      "image_0038_8.png niet Rajouri\n",
      "image_0038_9.png \n",
      "image_0039_0.png NEWS\n",
      "image_0039_1.png \n",
      "image_0039_10.png MAMATA 1\n",
      "image_0039_11.png \n",
      "image_0039_12.png \n",
      "image_0039_13.png \n",
      "image_0039_14.png \n",
      "image_0039_15.png PAK\n",
      "image_0039_16.png \n",
      "image_0039_17.png \n",
      "image_0039_18.png \n",
      "image_0039_2.png \n",
      "image_0039_3.png \n",
      "image_0039_4.png \n",
      "image_0039_5.png \n",
      "image_0039_6.png \n",
      "image_0039_7.png oonch- -Rajouri\n",
      "image_0039_8.png \n",
      "image_0039_9.png \n",
      "image_0040_0.png \n",
      "image_0040_1.png NEWS\n",
      "image_0040_10.png \n",
      "image_0040_11.png \n",
      "image_0040_2.png \n",
      "image_0040_3.png \n",
      "image_0040_4.png \n",
      "image_0040_5.png ree -Rajouri\n",
      "image_0040_6.png aap) | a’, 4-4\n",
      "A “— |\n",
      "image_0040_7.png PAK |\n",
      "image_0040_8.png \n",
      "image_0040_9.png \n",
      "image_0041_0.png \n",
      "image_0041_1.png \n",
      "image_0041_2.png \n",
      "image_0041_3.png \n",
      "image_0041_4.png \n",
      "image_0042_0.png \n",
      "image_0042_1.png \n",
      "image_0042_2.png \n",
      "image_0042_3.png \n",
      "image_0042_4.png \n",
      "image_0042_5.png \n",
      "image_0043_0.png \n",
      "image_0043_1.png PUNJABI\n",
      "image_0043_10.png —\n",
      "SPEED NE eee\n",
      "image_0043_2.png \n",
      "image_0043_3.png \n",
      "image_0043_4.png ACTOR\n",
      "image_0043_5.png wala\n",
      "image_0043_6.png 4th rie\n",
      "image_0043_7.png \n",
      "image_0043_8.png \n",
      "image_0043_9.png SILLED\n",
      "image_0044_0.png \n",
      "image_0044_1.png \n",
      "image_0044_10.png als\n",
      "image_0044_11.png \n",
      "image_0044_12.png \n",
      "image_0044_13.png KUSHAL\n",
      "image_0044_14.png Pts\n",
      "image_0044_15.png \n",
      "image_0044_16.png Eile\n",
      "image_0044_17.png \n",
      "image_0044_18.png \n",
      "image_0044_19.png \n",
      "image_0044_2.png \n",
      "image_0044_20.png bined\n",
      "ra\n",
      "image_0044_21.png f\n",
      "image_0044_22.png PL\n",
      "image_0044_3.png \n",
      "image_0044_4.png PUNJABI\n",
      "image_0044_5.png . KILLED\n",
      "image_0044_6.png a}\n",
      "\n",
      "&\n",
      "7\n",
      "image_0044_7.png \n",
      "image_0044_8.png ACTOR\n",
      "image_0044_9.png soldiers\n",
      "image_0045_0.png NEWS\n",
      "image_0045_1.png \n",
      "image_0045_10.png PJelitli- se\n",
      "image_0045_11.png \n",
      "image_0045_12.png oa 3\n",
      "image_0045_13.png \n",
      "image_0045_14.png 4th ia\n",
      "image_0045_15.png PA ets\n",
      "image_0045_16.png Eile\n",
      "image_0045_17.png \n",
      "image_0045_18.png PAK ‘|\n",
      "image_0045_19.png \n",
      "image_0045_2.png \n",
      "image_0045_20.png \n",
      "image_0045_21.png Sa tical\n",
      "image_0045_22.png \n",
      "image_0045_23.png AL\n",
      "image_0045_3.png \n",
      "image_0045_4.png PUNJABI\n",
      "image_0045_5.png . KILLED\n",
      "image_0045_6.png \n",
      "image_0045_7.png ACTOR\n",
      "image_0045_8.png a}\n",
      "image_0045_9.png \n",
      "image_0046_0.png NEWS\n",
      "image_0046_1.png \n",
      "image_0046_10.png \n",
      "image_0046_11.png “LIFE\n",
      "image_0046_12.png \n",
      "image_0046_13.png tlt\n",
      "\n",
      "ENDS\n",
      "image_0046_14.png \n",
      "image_0046_15.png isle\n",
      "image_0046_16.png \n",
      "image_0046_17.png \n",
      "image_0046_18.png \n",
      "image_0046_19.png \n",
      "image_0046_2.png \n",
      "image_0046_20.png \n",
      "image_0046_21.png \n",
      "image_0046_3.png \n",
      "image_0046_4.png PUNJABI\n",
      "image_0046_5.png \n",
      "image_0046_6.png \n",
      "image_0046_7.png a}\n",
      "image_0046_8.png KUSHAL\n",
      "image_0046_9.png soldiers\n",
      "image_0047_0.png NEWS\n",
      "image_0047_1.png \n",
      "image_0047_10.png \n",
      "image_0047_11.png Salsas\n",
      "image_0047_12.png \n",
      "image_0047_13.png \n",
      "image_0047_14.png \n",
      "image_0047_15.png \n",
      "image_0047_16.png ile\n",
      "image_0047_17.png \n",
      "image_0047_18.png \n",
      "image_0047_19.png ee\n",
      "image_0047_2.png \n",
      "image_0047_20.png \n",
      "image_0047_21.png \n",
      "image_0047_3.png \n",
      "image_0047_4.png PUNJABI\n",
      "image_0047_5.png , KILLED\n",
      "image_0047_6.png \n",
      "image_0047_7.png a}\n",
      "image_0047_8.png soldiers\n",
      "image_0047_9.png KUSHAL\n",
      "image_0048_0.png NEWS\n",
      "image_0048_1.png \n",
      "image_0048_10.png ‘LIFE\n",
      "image_0048_11.png \n",
      "image_0048_12.png \n",
      "image_0048_13.png ACTOR\n",
      "image_0048_14.png ‘killed |\n",
      "image_0048_15.png Eile\n",
      "image_0048_16.png \n",
      "image_0048_17.png \n",
      "image_0048_18.png \n",
      "image_0048_19.png FILE\n",
      "image_0048_2.png \n",
      "image_0048_20.png pasa\n",
      "image_0048_3.png \n",
      "image_0048_4.png \n",
      "image_0048_5.png aT mst\n"
     ]
    }
   ],
   "source": [
    "# I can use pytesseract, but I deem to use subprocess this time around ;)\n",
    "import subprocess\n",
    "\n",
    "for imgname in sorted(os.listdir('../results')):\n",
    "    process = subprocess.run(['tesseract', os.path.realpath(os.path.join('..', 'results', imgname)) \n",
    "                              ,'stdout'], stdout=subprocess.PIPE,\n",
    "                            universal_newlines=True)\n",
    "    output = process.stdout\n",
    "    print(f'{imgname} {output.rstrip()}')\n",
    "    \n",
    "#!tesseract ../results/* stdout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
